wandb_version: 1

Q_model:
  desc: null
  value:
    fcnet_activation: relu
    fcnet_hiddens:
    - 512
    - 512
    hidden_activation: -1
    hidden_layer_sizes: -1
_deterministic_loss:
  desc: null
  value: false
_use_beta_distribution:
  desc: null
  value: false
_wandb:
  desc: null
  value:
    cli_version: 0.9.2
    framework: torch
    is_jupyter_run: false
    is_kaggle_kernel: false
    python_version: 3.6.8
batch_mode:
  desc: null
  value: truncate_episodes
buffer_size:
  desc: null
  value: 1000000
clip_actions:
  desc: null
  value: true
clip_rewards:
  desc: null
  value: null
collect_metrics_timeout:
  desc: null
  value: 180
compress_observations:
  desc: null
  value: false
custom_eval_function:
  desc: null
  value: null
custom_resources_per_worker:
  desc: null
  value: {}
eager:
  desc: null
  value: false
eager_tracing:
  desc: null
  value: false
env:
  desc: null
  value: flatland_sparse
env_config:
  desc: null
  value:
    generator: sparse_rail_generator
    generator_config: small_v0
    observation: tree
    observation_config:
      max_depth: 3
      shortest_path_max_depth: 30
    wandb:
      entity: wullli
      project: flatland
      tags:
      - small_v0
      - tree_obs
      - sac
      - custom
    yaml_config: ../resources/experiments/custom/sac/sac_tree_obs_small_v0.yaml
evaluation_config:
  desc: null
  value: {}
evaluation_interval:
  desc: null
  value: null
evaluation_num_episodes:
  desc: null
  value: 10
evaluation_num_workers:
  desc: null
  value: 0
exploration_config:
  desc: null
  value:
    type: StochasticSampling
explore:
  desc: null
  value: true
extra_python_environs_for_driver:
  desc: null
  value: {}
extra_python_environs_for_worker:
  desc: null
  value: {}
final_prioritized_replay_beta:
  desc: null
  value: 0.4
gamma:
  desc: null
  value: 0.99
grad_clip:
  desc: null
  value: null
grad_norm_clipping:
  desc: null
  value: -1
horizon:
  desc: null
  value: null
ignore_worker_failures:
  desc: null
  value: false
in_evaluation:
  desc: null
  value: false
initial_alpha:
  desc: null
  value: 1.0
input:
  desc: null
  value: sampler
input_evaluation:
  desc: null
  value:
  - is
  - wis
learning_starts:
  desc: null
  value: 1500
local_tf_session_args:
  desc: null
  value:
    inter_op_parallelism_threads: 8
    intra_op_parallelism_threads: 8
log_level:
  desc: null
  value: WARN
log_sys_usage:
  desc: null
  value: true
lr:
  desc: null
  value: 0.0001
memory:
  desc: null
  value: 0
memory_per_worker:
  desc: null
  value: 0
metrics_smoothing_episodes:
  desc: null
  value: 100
min_iter_time_s:
  desc: null
  value: 1
model:
  desc: null
  value:
    conv_activation: relu
    conv_filters: null
    custom_action_dist: null
    custom_model: null
    custom_options: {}
    custom_preprocessor: null
    dim: 84
    fcnet_activation: tanh
    fcnet_hiddens:
    - 256
    - 256
    framestack: true
    free_log_std: false
    grayscale: false
    lstm_cell_size: 256
    lstm_use_prev_action_reward: false
    max_seq_len: 20
    no_final_linear: false
    state_shape: null
    use_lstm: false
    vf_share_layers: true
    zero_mean: true
monitor:
  desc: null
  value: false
multiagent:
  desc: null
  value:
    policies: {}
    policies_to_train: null
    policy_mapping_fn: null
n_step:
  desc: null
  value: 1
no_done_at_end:
  desc: null
  value: false
no_eager_on_workers:
  desc: null
  value: false
normalize_actions:
  desc: null
  value: false
num_cpus_for_driver:
  desc: null
  value: 1
num_cpus_per_worker:
  desc: null
  value: 1
num_envs_per_worker:
  desc: null
  value: 5
num_gpus:
  desc: null
  value: 1
num_gpus_per_worker:
  desc: null
  value: 0
num_workers:
  desc: null
  value: 7
object_store_memory:
  desc: null
  value: 0
object_store_memory_per_worker:
  desc: null
  value: 0
observation_filter:
  desc: null
  value: NoFilter
optimization:
  desc: null
  value:
    actor_learning_rate: 0.0003
    critic_learning_rate: 0.0003
    entropy_learning_rate: 0.0003
optimizer:
  desc: null
  value: {}
output:
  desc: null
  value: null
output_compress_columns:
  desc: null
  value:
  - obs
  - new_obs
output_max_file_size:
  desc: null
  value: 67108864
policy_model:
  desc: null
  value:
    fcnet_activation: relu
    fcnet_hiddens:
    - 512
    - 512
    hidden_activation: -1
    hidden_layer_sizes: -1
postprocess_inputs:
  desc: null
  value: false
preprocessor_pref:
  desc: null
  value: deepmind
prioritized_replay:
  desc: null
  value: false
prioritized_replay_alpha:
  desc: null
  value: 0.6
prioritized_replay_beta:
  desc: null
  value: 0.4
prioritized_replay_beta_annealing_timesteps:
  desc: null
  value: 20000
prioritized_replay_eps:
  desc: null
  value: 1.0e-06
remote_env_batch_wait_ms:
  desc: null
  value: 0
remote_worker_envs:
  desc: null
  value: false
rollout_fragment_length:
  desc: null
  value: 1
sample_async:
  desc: null
  value: false
sample_batch_size:
  desc: null
  value: -1
seed:
  desc: null
  value: null
shuffle_buffer_size:
  desc: null
  value: 0
soft_horizon:
  desc: null
  value: false
synchronize_filters:
  desc: null
  value: true
target_entropy:
  desc: null
  value: auto
target_network_update_freq:
  desc: null
  value: 0
tau:
  desc: null
  value: 0.005
tf_session_args:
  desc: null
  value:
    allow_soft_placement: true
    device_count:
      CPU: 1
    gpu_options:
      allow_growth: true
    inter_op_parallelism_threads: 2
    intra_op_parallelism_threads: 2
    log_device_placement: false
timesteps_per_iteration:
  desc: null
  value: 100
train_batch_size:
  desc: null
  value: 256
twin_q:
  desc: null
  value: true
use_exec_api:
  desc: null
  value: false
use_pytorch:
  desc: null
  value: false
use_state_preprocessor:
  desc: null
  value: false
worker_side_prioritization:
  desc: null
  value: false
