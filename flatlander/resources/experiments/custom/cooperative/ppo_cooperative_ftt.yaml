flatland-sparse-scaling-cooperative-ftt-ppo:
    run: TTFPPO
    env: flatland_sparse
    stop:
        timesteps_total: 15000000  # 15e6
    checkpoint_freq: 10
    checkpoint_at_end: True
    keep_checkpoints_num: 20
    checkpoint_score_attr: episode_reward_mean
    num_samples: 1
    config:
        num_workers: 1
        num_envs_per_worker: 1
        num_gpus: 0

        gamma: 0.9999

        clip_rewards: False
        vf_clip_param: 500.0
        entropy_coeff: 0.01
        # effective batch_size: train_batch_size * num_agents_in_each_environment [5, 10]
        # see https://github.com/ray-project/ray/issues/4628
        train_batch_size: 1000  # 5000
        rollout_fragment_length: 50  # 100
        sgd_minibatch_size: 100  # 500
        vf_share_layers: False

        env_config:
            observation: fixed_tree
            observation_config:
                max_depth: 2
                shortest_path_max_depth: 30
                small_tree: False

            generator: sparse_rail_generator
            generator_config: small_v0

            skip_no_choice_cells: True
            accumulate_skipped_rewards: True
            available_actions_obs: True
            allow_noop: False

            add_agent_interval: 5000 # beware of the n_envs and number workers
            interval_growth_rate: 1.25
            max_agents: 10

            wandb:
                project: flatland
                entity: wullli
                tags: ["ppo", "medium_scaling_v0", "cooperative", "tree", "transformer", "custom"]

        model:
            custom_model: cooperative_ftt
            custom_options:
                warmup_steps: 50000
                mask_unavailable_actions: True
                transformer:
                    use_cnn_decoding: False
                    policy_layers:
                        - 256
                        - 256
                    value_layers:
                        - 256
                        - 256
                    encoder_layer_neurons: 512
                    num_heads: 11
                    num_encoder_layers: 2
                    dropout_rate: 0.1


